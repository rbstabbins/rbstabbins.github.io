---
layout: page
title: About
permalink: /about/
order: 1
---

<img style="float: left; padding: 10px;" width="35%" src="profile_2.jpg" alt="Portrait" >

I'm interested in how we can use robotic avatars to visually explore remote places in the Solar System, so that we can better understand where we came from and where we're going.

<!-- I was born in London but grew up in Cornwall, in the Helford area, next to the sea and under the stars.
I did a lot of sailing growing up, through the Optimist and Laser National junior and youth programmes, but then became more interested in music, in the orbit of the Falmouth scene circa-2010. -->
I studied Physics in London at UCL from 2010 - 2014, developing an interest in robotics through an internship with the Autonomous Systems Group at RAL Space, and an interest in space instrumentation and imaging during my Masters thesis.
&nbsp;

In 2014 I joined the Media & Arts Technology Centre for Doctoral Training in EECS at QMUL to pursue my intersts in digital musical instruments. I learned a lot about programming (C++, MaxMSP, Arduino) and human-computer interaction, but most importantly I learned that I needed to be working in the space domain.
<!-- I sat the Masters year, completing modules in Interaction Design, C++ for Image Processing and various mandatory courses in audio, interactive media and research methods, and I was lucky enough to spend a summer on placement in the heart of SoHo in the offices of M&C Saatchi, where Dave Cox let me play with Unity and hobby drone kits in an attempt to build a haptic torque controller for virtual reality. -->
&nbsp;

After leaving QMUL, in 2015 I was offered a place in the Planetary Science Group at University College London's [Mullard Space Science Laboratory](https://www.ucl.ac.uk/mssl/mullard-space-science-laboratory), to join the team preparing for the operation of the panoramic multispectral-stereo camera system, [PanCam](https://exploration.esa.int/web/mars/-/45103-rover-instruments?section=pancam---the-panoramic-camera), for ESA's [ExoMars 2022 Rover](https://exploration.esa.int/web/mars/-/48088-mission-overview), under the supervision of Andrew Coates.
&nbsp;

For my thesis I focused on modelling the response function of PanCam, producing a mathematical model of the system optics and detector, and implementing this in a software simulator. I used this simulator to help develop the auto-exposure algorithm of the camera, and to investigate the effects of noise and nonlinearity on the calibration process. I also used this to inform my contributions to the ExoSpec toolkit for spectral image analysis.
&nbsp;

I joined Peter Grindrod's Planetary Surfaces Group at the Natural History Museum in London in 2019, to continue preparations for spectral imaging with PanCam. In this work, I've been investigating how we can use prior knowledge of the landing site to guide our selection of combinations of spectral filters for efficiently chracterising the geology that the ExoMars rover will explore.
&nbsp;

Some of the things I spend time thinking about include light-matter interactions, detector system electronics, undersampled noisey signals, the automation of exploration, team operations, digital image processing, the perception of colour, visual cognition, and life in the universe.
&nbsp;
